### 双向验证的FL

##### 1.实现ImprovedPaillier、SafeMul、Threshold工具类。<u>*<!--完成-->*</u>

##### 2.基于工具类完成TA、CSP、DO、Test代码的实现。<!--完成-->

##### 3.Test模拟FL实现的基础上，支持DO掉线、增加SafeMul的使用。*<!--完成-->*

> [!NOTE]
>
> ##### ####完成了基本框架####
>
> ##### ###仔细验证代码，检查功能的正确使用，同时考虑几个问题：###
>
> ##### ###1）模型参数/正交向量组的替换是否可以顺利实现？###
>
> ##### ###2）更换使用真实的训练场景###

##### 4.使用真正的神经网络训练

##### 5.正交向量投毒检测

​	--1）正交向量乘积检验通过、投毒检测通过

​	--2）正交向量乘积检验通过、投毒检测不通过——》投毒检测定位恶意DO

​	--3）正交向量乘积检验不通过、投毒检测通过——》二分查找恶意DO

######################################################################

######################################################################

> [!NOTE]
>
> 二分查找恶意DO？：直接从头开始二分，即，CSP一次向一半的DO发起整个请求，重新构建一半DO的密文、一半DO的安全点积，然后验证。
>
> 
>
> CSP如何验证正交向量乘积正确？
>
> --CSP此时拥有聚合的模型参数、拥有自己的正交向量组
>
> --DO拥有自己的模型参数、自己的正交向量组
>
> 1.CSP把自己的正交向量组【一轮】发给DO，
>
> 2.DO乘自己的模型参数然后发过去密文结果【二轮】和自己的正交向量组*自己的模型参数【明文算】
>
> 3.CSP接收后【三轮】解密，加上另一部分，得到结果。
>
> ##此时，CSP得到了每个DO的模型参数与整个正交向量组的点积结果
>
> 4.CSP发送聚合解密后的明文模型参数，DO乘完发给CSP，CSP解密再与自己的相乘。最后相加。？

![image-20251118155624924](C:\Users\leg\AppData\Roaming\Typora\typora-user-images\image-20251118155624924.png)



### 投毒检测

防御方案：

**FedAvg**

- 普通联邦平均，无任何防御，作为**不鲁棒基线**。

**Trimmed Mean（TrMean）**

- 典型 **coordinate-wise 鲁棒聚合**。
- 每一维上丢掉若干个最大值和最小值，再对剩下的取平均，目的是过滤掉特别极端的恶意值。

**Geometric median（GeoMed）**

- **model-wise 鲁棒聚合**。
- 找到一个点，让它到所有客户端更新向量的距离和最小（几何中位数），这个点对极端 outlier 不敏感。

**Multi-Krum**

- **距离型、model-wise 鲁棒方法**。
- 计算每个客户端更新与其它更新的距离，把“离大家都不远”的那些更新选出来做平均，试图过滤掉孤立的恶意更新。

**Bulyan**

- 在 Krum/Multi-Krum 的基础上，再做一层坐标-截断，简单说就是：
  1. 用 Krum 反复选出一批“相对可信”的客户端；
  2. 再对这些客户端的各坐标做 trimmed mean。
- 兼具 model-wise + coordinate-wise 的特性。

**DnC（Divide-and-Conquer）** [arXiv](https://arxiv.org/pdf/2409.01435)

- 将客户端更新做聚类，利用“多数诚实、少数恶意”的假设，丢掉异常簇，再在剩下的簇中聚合。

**SignGuard** [arXiv+1](https://arxiv.org/pdf/2409.01435)

- 这篇文章引用的一个 SOTA 防御。
- 核心思想：
  - 使用**方向（sign）+ 模长（magnitude）** 的信息进行聚类和过滤；
  - 尝试识别那些在符号模式上偏离大多数诚实客户端的更新，再结合模长做过滤。

**SparseFed** [arXiv](https://arxiv.org/pdf/2409.01435)

- 典型的 **sparsification-based 防御**。
- 在服务器端对聚合后的模型做剪枝（去掉小参数），结合 clipping 与误差反馈，希望弱化恶意参数的影响。

**LASA（作者提出的方法）** [arXiv](https://arxiv.org/pdf/2409.01435)

- 防御策略可以理解为两步：
  1. **Pre-aggregation sparsification**：对每个客户端更新单独做剪枝，仅保留最重要的参数（每个客户端有各自的掩码）；
  2. **Layer-wise adaptive filtering**：在每一层上，用“方向 + 模长”的指标选择看起来是**诚实的层**来参与聚合，过滤掉可疑层。



# 投毒方案：

### 3.1 Naive attacks（三种）

这些是比较“粗暴”的攻击方式，用来测防御在简单场景下的表现：

1. **Random attack**
   - 恶意客户端不管本地数据，直接上传随机向量当作模型更新（比如高斯随机向量）。
   - 非常容易被任何稍微鲁棒一点的聚合方法识别为 outlier。
2. **Noise attack**
   - 在本地正常更新的基础上，加上很大的噪声（比如高方差高斯噪声），使得上传的更新被严重扰动。
   - 依然比较容易被基于距离或截断的方法滤掉。
3. **Sign-flip attack**
   - 把正常更新的**符号取反并且放大**（例如乘上一个负的大系数），相当于沿着“正确方向”的反方向用力推模型。
   - 比 Random/Noise 稍微“聪明”一点，但形状仍然明显异常。

### 3.2 SOTA attacks（五种）

这五种都是在前人工作中被证明对鲁棒聚合非常强的 **Byzantine 攻击**：[arXiv+1](https://arxiv.org/pdf/2409.01435)

1. **TailoredTrMean（AGR-tailored Trimmed-mean attack）**
   - 出自 [45]，专门“对着 Trimmed Mean 这种聚合器来设计的攻击”。
   - 攻击者精心选择更新值，让自己大部分维度落在“不会被截断”的区间内，但整体方向仍朝着破坏模型的方向偏移，从而骗过 TrMean。
2. **Min-Max attack**
   - 同样来自 [45]。
   - 利用“**最大化/最小化距离**”的思路构造恶意更新，让恶意集体在“被聚合器选中的那一侧”，同时又足够集中，难以被看成 outlier。
   - 对 Multi-Krum、距离型防御特别难搞。
3. **Min-Sum attack**
   - 也是 [45]。
   - 和 Min-Max 类似，目标是最小化到诚实更新的距离和（或者在某些度量下显得“很像诚实更新”），从而在聚合时占大权重，但方向又是有害的。
4. **Lie attack**（来自 [5]）
   - 攻击者先“估计”诚实客户端更新的大致均值方向，再在这个方向上 **适度夸大或扭曲** 自己的更新。
   - 这样既能在几何上看起来像多数诚实客户端，又能慢慢把整体梯度推向错误的方向。
5. **ByzMean attack**（来自 SignGuard 的论文 [58]）
   - 利用聚合器的结构（特别是基于 sign/clustering 的防御）设计的攻击。
   - 通过让恶意更新和诚实更新在符号模式上高度相似，但在模长或局部维度上有策略性的偏移，来逃避基于 sign 的过滤。
